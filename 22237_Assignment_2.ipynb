{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOuVerYr2DnaHpj6yrU22vS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A23929/MDSC-302-Assignments/blob/main/22237_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGYF58DA2tN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93b5cb5f-e78a-495f-8e5c-387187364fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 75528483.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 132244207.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 23726324.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 20484439.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.9*(len(training_data)))"
      ],
      "metadata": {
        "id": "phtEcwM2-81d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_size = len(training_data) - train_size"
      ],
      "metadata": {
        "id": "WXw-Fc-y_kgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, val_set = random_split(training_data, [train_size, val_size])"
      ],
      "metadata": {
        "id": "qz16rNyh_z7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2nWqlsUAFod",
        "outputId": "7e7a162e-763f-4236-abe6-7c2afb848a67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "54000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_set.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4-YQ8F5ALoW",
        "outputId": "03039601-8567-424f-c40f-8fc5e0794416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(training_data,batch_size = 64,shuffle=True)\n",
        "test_dataloader = DataLoader(test_data,batch_size = 64,shuffle=True)\n",
        "val_dataloader = DataLoader(val_set,batch_size = 64,shuffle=True)"
      ],
      "metadata": {
        "id": "ZqOP4gVr4f12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features,train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img,cmap='gray')\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "DtB3F6LA-QwV",
        "outputId": "fa96a236-d5ff-419d-8b07-cd2f012108d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "0xGD_SMJAQRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqr25j4qBbNW",
        "outputId": "242b4cc6-08f7-4701-d3e1-0249c76ce312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "jFuGWzd1C0TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()"
      ],
      "metadata": {
        "id": "QbJOBAtoceXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "_cP8t-bdct-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "UMNR6vyIcxME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "M4OwF2IAc080"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  # Set the model to training mode - important for batch normalization and dropout layers\n",
        "  # Unnecessary in this situation but added for best practices\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    # Compute prediction and loss\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      loss, current = loss.item(), (batch + 1) * len(X)\n",
        "      print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "  # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "  # Unnecessary in this situation but added for best practices\n",
        "  model.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "  # Also serves to reduce unnecessary gradient computations and memory usage for tensors\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test error : \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "def val_loop(dataloader, model, loss_fn):\n",
        "  # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "  # Unnecessary in this situation but added for best practices\n",
        "  model.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "  # Also serves to reduce unnecessary gradient computations and memory usage for tensors\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Validation error : \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "Eukp0oFhc26M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 20\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n------------------------------------------\")\n",
        "  train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "  val_loop(val_dataloader, model, loss_fn)\n",
        "  test_loop(test_dataloader, model, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV83BSH1vsFE",
        "outputId": "d12056b9-1e03-4019-8549-6dda9f1f575c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "------------------------------------------\n",
            "loss: 2.304466 [   64/60000]\n",
            "loss: 2.300231 [ 6464/60000]\n",
            "loss: 2.294884 [12864/60000]\n",
            "loss: 2.286346 [19264/60000]\n",
            "loss: 2.286783 [25664/60000]\n",
            "loss: 2.280002 [32064/60000]\n",
            "loss: 2.271542 [38464/60000]\n",
            "loss: 2.266351 [44864/60000]\n",
            "loss: 2.276125 [51264/60000]\n",
            "loss: 2.270389 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 49.5%, Avg loss: 2.262115 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 51.0%, Avg loss: 2.260840 \n",
            "\n",
            "Epoch 2\n",
            "------------------------------------------\n",
            "loss: 2.268809 [   64/60000]\n",
            "loss: 2.255421 [ 6464/60000]\n",
            "loss: 2.252072 [12864/60000]\n",
            "loss: 2.249449 [19264/60000]\n",
            "loss: 2.239784 [25664/60000]\n",
            "loss: 2.236688 [32064/60000]\n",
            "loss: 2.230093 [38464/60000]\n",
            "loss: 2.210936 [44864/60000]\n",
            "loss: 2.215844 [51264/60000]\n",
            "loss: 2.216633 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 63.2%, Avg loss: 2.203293 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 63.5%, Avg loss: 2.200460 \n",
            "\n",
            "Epoch 3\n",
            "------------------------------------------\n",
            "loss: 2.209453 [   64/60000]\n",
            "loss: 2.205516 [ 6464/60000]\n",
            "loss: 2.188248 [12864/60000]\n",
            "loss: 2.151611 [19264/60000]\n",
            "loss: 2.163575 [25664/60000]\n",
            "loss: 2.162841 [32064/60000]\n",
            "loss: 2.157295 [38464/60000]\n",
            "loss: 2.139499 [44864/60000]\n",
            "loss: 2.118877 [51264/60000]\n",
            "loss: 2.098805 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 66.7%, Avg loss: 2.103280 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 67.3%, Avg loss: 2.097779 \n",
            "\n",
            "Epoch 4\n",
            "------------------------------------------\n",
            "loss: 2.094799 [   64/60000]\n",
            "loss: 2.089223 [ 6464/60000]\n",
            "loss: 2.057051 [12864/60000]\n",
            "loss: 2.097399 [19264/60000]\n",
            "loss: 2.079715 [25664/60000]\n",
            "loss: 2.050899 [32064/60000]\n",
            "loss: 2.000350 [38464/60000]\n",
            "loss: 1.951939 [44864/60000]\n",
            "loss: 1.995784 [51264/60000]\n",
            "loss: 1.924273 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 67.6%, Avg loss: 1.922907 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 68.2%, Avg loss: 1.912711 \n",
            "\n",
            "Epoch 5\n",
            "------------------------------------------\n",
            "loss: 1.903746 [   64/60000]\n",
            "loss: 1.804872 [ 6464/60000]\n",
            "loss: 1.854369 [12864/60000]\n",
            "loss: 1.889639 [19264/60000]\n",
            "loss: 1.862371 [25664/60000]\n",
            "loss: 1.751063 [32064/60000]\n",
            "loss: 1.686411 [38464/60000]\n",
            "loss: 1.684125 [44864/60000]\n",
            "loss: 1.636060 [51264/60000]\n",
            "loss: 1.669178 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 69.3%, Avg loss: 1.635652 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 69.7%, Avg loss: 1.619957 \n",
            "\n",
            "Epoch 6\n",
            "------------------------------------------\n",
            "loss: 1.648541 [   64/60000]\n",
            "loss: 1.587586 [ 6464/60000]\n",
            "loss: 1.526649 [12864/60000]\n",
            "loss: 1.536389 [19264/60000]\n",
            "loss: 1.466056 [25664/60000]\n",
            "loss: 1.558446 [32064/60000]\n",
            "loss: 1.429931 [38464/60000]\n",
            "loss: 1.372673 [44864/60000]\n",
            "loss: 1.252727 [51264/60000]\n",
            "loss: 1.326701 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 73.5%, Avg loss: 1.308138 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 74.2%, Avg loss: 1.290595 \n",
            "\n",
            "Epoch 7\n",
            "------------------------------------------\n",
            "loss: 1.419032 [   64/60000]\n",
            "loss: 1.366023 [ 6464/60000]\n",
            "loss: 1.240856 [12864/60000]\n",
            "loss: 1.277208 [19264/60000]\n",
            "loss: 1.138399 [25664/60000]\n",
            "loss: 1.138101 [32064/60000]\n",
            "loss: 1.085447 [38464/60000]\n",
            "loss: 1.171394 [44864/60000]\n",
            "loss: 1.010838 [51264/60000]\n",
            "loss: 1.128512 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 78.7%, Avg loss: 1.044366 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 79.0%, Avg loss: 1.027697 \n",
            "\n",
            "Epoch 8\n",
            "------------------------------------------\n",
            "loss: 1.153569 [   64/60000]\n",
            "loss: 1.061355 [ 6464/60000]\n",
            "loss: 0.900995 [12864/60000]\n",
            "loss: 0.888468 [19264/60000]\n",
            "loss: 0.990781 [25664/60000]\n",
            "loss: 1.086815 [32064/60000]\n",
            "loss: 1.042533 [38464/60000]\n",
            "loss: 0.981387 [44864/60000]\n",
            "loss: 0.847226 [51264/60000]\n",
            "loss: 1.082217 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 81.4%, Avg loss: 0.863302 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 81.3%, Avg loss: 0.852279 \n",
            "\n",
            "Epoch 9\n",
            "------------------------------------------\n",
            "loss: 0.833562 [   64/60000]\n",
            "loss: 0.697759 [ 6464/60000]\n",
            "loss: 0.770531 [12864/60000]\n",
            "loss: 0.880132 [19264/60000]\n",
            "loss: 0.714813 [25664/60000]\n",
            "loss: 0.885286 [32064/60000]\n",
            "loss: 0.849951 [38464/60000]\n",
            "loss: 0.946006 [44864/60000]\n",
            "loss: 0.927348 [51264/60000]\n",
            "loss: 0.631083 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 83.0%, Avg loss: 0.740824 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 83.2%, Avg loss: 0.734789 \n",
            "\n",
            "Epoch 10\n",
            "------------------------------------------\n",
            "loss: 0.679200 [   64/60000]\n",
            "loss: 0.695058 [ 6464/60000]\n",
            "loss: 0.737983 [12864/60000]\n",
            "loss: 0.810703 [19264/60000]\n",
            "loss: 0.582010 [25664/60000]\n",
            "loss: 0.669729 [32064/60000]\n",
            "loss: 0.855623 [38464/60000]\n",
            "loss: 0.657190 [44864/60000]\n",
            "loss: 0.688236 [51264/60000]\n",
            "loss: 0.487472 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 84.2%, Avg loss: 0.655403 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 84.4%, Avg loss: 0.648322 \n",
            "\n",
            "Epoch 11\n",
            "------------------------------------------\n",
            "loss: 0.653573 [   64/60000]\n",
            "loss: 0.731356 [ 6464/60000]\n",
            "loss: 0.627858 [12864/60000]\n",
            "loss: 0.829756 [19264/60000]\n",
            "loss: 0.717609 [25664/60000]\n",
            "loss: 0.526703 [32064/60000]\n",
            "loss: 0.576994 [38464/60000]\n",
            "loss: 0.639748 [44864/60000]\n",
            "loss: 0.557131 [51264/60000]\n",
            "loss: 0.686815 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 85.3%, Avg loss: 0.593003 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 85.6%, Avg loss: 0.587869 \n",
            "\n",
            "Epoch 12\n",
            "------------------------------------------\n",
            "loss: 0.607908 [   64/60000]\n",
            "loss: 0.611133 [ 6464/60000]\n",
            "loss: 0.506065 [12864/60000]\n",
            "loss: 0.484685 [19264/60000]\n",
            "loss: 0.651120 [25664/60000]\n",
            "loss: 0.528585 [32064/60000]\n",
            "loss: 0.480355 [38464/60000]\n",
            "loss: 0.413579 [44864/60000]\n",
            "loss: 0.433102 [51264/60000]\n",
            "loss: 0.554897 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 86.2%, Avg loss: 0.546124 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 86.5%, Avg loss: 0.542709 \n",
            "\n",
            "Epoch 13\n",
            "------------------------------------------\n",
            "loss: 0.631006 [   64/60000]\n",
            "loss: 0.539169 [ 6464/60000]\n",
            "loss: 0.495352 [12864/60000]\n",
            "loss: 0.572272 [19264/60000]\n",
            "loss: 0.705178 [25664/60000]\n",
            "loss: 0.683503 [32064/60000]\n",
            "loss: 0.626857 [38464/60000]\n",
            "loss: 0.535155 [44864/60000]\n",
            "loss: 0.586459 [51264/60000]\n",
            "loss: 0.393782 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 86.8%, Avg loss: 0.509730 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 87.0%, Avg loss: 0.506386 \n",
            "\n",
            "Epoch 14\n",
            "------------------------------------------\n",
            "loss: 0.609570 [   64/60000]\n",
            "loss: 0.492953 [ 6464/60000]\n",
            "loss: 0.417455 [12864/60000]\n",
            "loss: 0.541236 [19264/60000]\n",
            "loss: 0.542557 [25664/60000]\n",
            "loss: 0.714088 [32064/60000]\n",
            "loss: 0.424969 [38464/60000]\n",
            "loss: 0.621439 [44864/60000]\n",
            "loss: 0.428390 [51264/60000]\n",
            "loss: 0.488526 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 87.2%, Avg loss: 0.481600 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 87.6%, Avg loss: 0.479840 \n",
            "\n",
            "Epoch 15\n",
            "------------------------------------------\n",
            "loss: 0.322276 [   64/60000]\n",
            "loss: 0.372205 [ 6464/60000]\n",
            "loss: 0.499219 [12864/60000]\n",
            "loss: 0.534492 [19264/60000]\n",
            "loss: 0.546453 [25664/60000]\n",
            "loss: 0.474810 [32064/60000]\n",
            "loss: 0.513728 [38464/60000]\n",
            "loss: 0.366284 [44864/60000]\n",
            "loss: 0.397006 [51264/60000]\n",
            "loss: 0.625117 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 87.5%, Avg loss: 0.456861 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 88.1%, Avg loss: 0.455722 \n",
            "\n",
            "Epoch 16\n",
            "------------------------------------------\n",
            "loss: 0.598935 [   64/60000]\n",
            "loss: 0.552362 [ 6464/60000]\n",
            "loss: 0.458213 [12864/60000]\n",
            "loss: 0.371532 [19264/60000]\n",
            "loss: 0.583540 [25664/60000]\n",
            "loss: 0.746979 [32064/60000]\n",
            "loss: 0.419251 [38464/60000]\n",
            "loss: 0.391729 [44864/60000]\n",
            "loss: 0.529713 [51264/60000]\n",
            "loss: 0.282019 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 88.1%, Avg loss: 0.437884 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 88.5%, Avg loss: 0.437833 \n",
            "\n",
            "Epoch 17\n",
            "------------------------------------------\n",
            "loss: 0.329396 [   64/60000]\n",
            "loss: 0.364957 [ 6464/60000]\n",
            "loss: 0.438721 [12864/60000]\n",
            "loss: 0.586573 [19264/60000]\n",
            "loss: 0.564008 [25664/60000]\n",
            "loss: 0.407548 [32064/60000]\n",
            "loss: 0.475390 [38464/60000]\n",
            "loss: 0.432995 [44864/60000]\n",
            "loss: 0.395427 [51264/60000]\n",
            "loss: 0.402776 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 88.3%, Avg loss: 0.421739 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 88.6%, Avg loss: 0.422169 \n",
            "\n",
            "Epoch 18\n",
            "------------------------------------------\n",
            "loss: 0.580440 [   64/60000]\n",
            "loss: 0.484997 [ 6464/60000]\n",
            "loss: 0.514203 [12864/60000]\n",
            "loss: 0.493421 [19264/60000]\n",
            "loss: 0.290491 [25664/60000]\n",
            "loss: 0.436371 [32064/60000]\n",
            "loss: 0.271775 [38464/60000]\n",
            "loss: 0.436102 [44864/60000]\n",
            "loss: 0.258248 [51264/60000]\n",
            "loss: 0.584666 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 88.4%, Avg loss: 0.408234 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 88.9%, Avg loss: 0.409136 \n",
            "\n",
            "Epoch 19\n",
            "------------------------------------------\n",
            "loss: 0.578611 [   64/60000]\n",
            "loss: 0.526495 [ 6464/60000]\n",
            "loss: 0.438987 [12864/60000]\n",
            "loss: 0.300616 [19264/60000]\n",
            "loss: 0.397056 [25664/60000]\n",
            "loss: 0.339173 [32064/60000]\n",
            "loss: 0.418571 [38464/60000]\n",
            "loss: 0.338632 [44864/60000]\n",
            "loss: 0.597700 [51264/60000]\n",
            "loss: 0.336441 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 88.8%, Avg loss: 0.395545 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 89.2%, Avg loss: 0.396203 \n",
            "\n",
            "Epoch 20\n",
            "------------------------------------------\n",
            "loss: 0.344407 [   64/60000]\n",
            "loss: 0.418229 [ 6464/60000]\n",
            "loss: 0.535207 [12864/60000]\n",
            "loss: 0.426869 [19264/60000]\n",
            "loss: 0.447913 [25664/60000]\n",
            "loss: 0.402733 [32064/60000]\n",
            "loss: 0.408433 [38464/60000]\n",
            "loss: 0.275436 [44864/60000]\n",
            "loss: 0.330669 [51264/60000]\n",
            "loss: 0.464503 [57664/60000]\n",
            "Validation error : \n",
            " Accuracy: 89.1%, Avg loss: 0.385249 \n",
            "\n",
            "Test error : \n",
            " Accuracy: 89.4%, Avg loss: 0.387670 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}